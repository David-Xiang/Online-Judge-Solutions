{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUse7Ep-Tl7j",
        "outputId": "2fc53559-2077-447b-f355-777191edc39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chalk-planar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for chalk-diagrams (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qqq git+https://github.com/chalk-diagrams/planar git+https://github.com/danoneata/chalk@srush-patch-1\n",
        "!wget -q https://github.com/srush/GPU-Puzzles/raw/main/robot.png https://github.com/srush/GPU-Puzzles/raw/main/lib.py\n",
        "!sed -i '448i\\            return' lib.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "import numpy as np\n",
        "import warnings\n",
        "from lib import CudaProblem, Coord\n",
        "warnings.filterwarnings(\n",
        "    action=\"ignore\", category=numba.NumbaPerformanceWarning, module=\"numba\"\n",
        ")"
      ],
      "metadata": {
        "id": "1-eKkogMTw50"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P1\n",
        "def map_spec(a):\n",
        "    return a + 10\n",
        "\n",
        "\n",
        "def map_test(cuda):\n",
        "    def call(out, a) -> None:\n",
        "        local_i = cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 1 lines)\n",
        "        out[local_i] = a[local_i] + 10\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 4\n",
        "out = np.zeros((SIZE,))\n",
        "a = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Map\", map_test, [a], out, threadsperblock=Coord(SIZE, 1), spec=map_spec\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Fox8Y8K7T7mW",
        "outputId": "972f2cb6-5782-4d2b-f071-83ba656bf061"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P2\n",
        "def zip_spec(a, b):\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def zip_test(cuda):\n",
        "    def call(out, a, b) -> None:\n",
        "        local_i = cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 1 lines)\n",
        "        out[local_i] = a[local_i] + b[local_i]\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 4\n",
        "out = np.zeros((SIZE,))\n",
        "a = np.arange(SIZE)\n",
        "b = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Zip\", zip_test, [a, b], out, threadsperblock=Coord(SIZE, 1), spec=zip_spec\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "9aYaCTk4UDaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88316a29-a558-43b3-89c4-02a33d406f64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P3\n",
        "def map_guard_test(cuda):\n",
        "    def call(out, a, size) -> None:\n",
        "        local_i = cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 2 lines)\n",
        "        if local_i < size:\n",
        "            out[local_i] = a[local_i] + 10\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 4\n",
        "out = np.zeros((SIZE,))\n",
        "a = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Guard\",\n",
        "    map_guard_test,\n",
        "    [a],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    threadsperblock=Coord(8, 1),\n",
        "    spec=map_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "21GSG9bHUJnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1abaf4c-23fc-4029-bcd9-df98fd258cb4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P4\n",
        "def map_2D_test(cuda):\n",
        "    def call(out, a, size) -> None:\n",
        "        local_i = cuda.threadIdx.x\n",
        "        local_j = cuda.threadIdx.y\n",
        "        # FILL ME IN (roughly 2 lines)\n",
        "        if local_i < size and local_j < size:\n",
        "            out[local_i, local_j] = a[local_i, local_j] + 10\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 2\n",
        "out = np.zeros((SIZE, SIZE))\n",
        "a = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
        "problem = CudaProblem(\n",
        "    \"Map 2D\", map_2D_test, [a], out, [SIZE], threadsperblock=Coord(3, 3), spec=map_spec\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "SQdmb_6zUN2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1de1985-4cef-42b6-c1ac-6a205d2214d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P5\n",
        "def broadcast_test(cuda):\n",
        "    def call(out, a, b, size) -> None:\n",
        "        local_i = cuda.threadIdx.x\n",
        "        local_j = cuda.threadIdx.y\n",
        "        # FILL ME IN (roughly 2 lines)\n",
        "        if local_i < size and local_j < size:\n",
        "            out[local_i, local_j] = a[local_i, 0] + b[0, local_j]\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 2\n",
        "out = np.zeros((SIZE, SIZE))\n",
        "a = np.arange(SIZE).reshape(SIZE, 1)\n",
        "b = np.arange(SIZE).reshape(1, SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Broadcast\",\n",
        "    broadcast_test,\n",
        "    [a, b],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    threadsperblock=Coord(3, 3),\n",
        "    spec=zip_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "A6q-Pk-1UR1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8074df0-3095-4f3f-e6c2-bbd6b8f55a08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P6\n",
        "def map_block_test(cuda):\n",
        "    def call(out, a, size) -> None:\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 2 lines)\n",
        "        if i < size:\n",
        "            out[i] = a[i] + 10\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 9\n",
        "out = np.zeros((SIZE,))\n",
        "a = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Blocks\",\n",
        "    map_block_test,\n",
        "    [a],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    threadsperblock=Coord(4, 1),\n",
        "    blockspergrid=Coord(3, 1),\n",
        "    spec=map_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fIgBIP1zYrwS",
        "outputId": "c4686815-870c-43fa-e46f-44d244fae8cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P7\n",
        "def map_block2D_test(cuda):\n",
        "    def call(out, a, size) -> None:\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 4 lines)\n",
        "        j = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "        if i < size and j < size:\n",
        "            out[i, j] = a[i, j] + 10\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 5\n",
        "out = np.zeros((SIZE, SIZE))\n",
        "a = np.ones((SIZE, SIZE))\n",
        "\n",
        "problem = CudaProblem(\n",
        "    \"Blocks 2D\",\n",
        "    map_block2D_test,\n",
        "    [a],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    threadsperblock=Coord(3, 3),\n",
        "    blockspergrid=Coord(2, 2),\n",
        "    spec=map_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pzuAUxVVZgQ_",
        "outputId": "9d48a69e-942f-4a3f-befc-e84a4afc5e95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P8\n",
        "TPB = 4\n",
        "def shared_test(cuda):\n",
        "    def call(out, a, size) -> None:\n",
        "        shared = cuda.shared.array(TPB, numba.float32)\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        local_i = cuda.threadIdx.x\n",
        "\n",
        "        if i < size:\n",
        "            shared[local_i] = a[i]\n",
        "\n",
        "        # FILL ME IN (roughly 2 lines)\n",
        "        cuda.syncthreads()\n",
        "        if i < size:\n",
        "            out[i] = shared[local_i] + 10\n",
        "\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 8\n",
        "out = np.zeros(SIZE)\n",
        "a = np.ones(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Shared\",\n",
        "    shared_test,\n",
        "    [a],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    threadsperblock=Coord(TPB, 1),\n",
        "    blockspergrid=Coord(2, 1),\n",
        "    spec=map_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XgS9QTWJaBaq",
        "outputId": "643773fa-44c3-48c4-8feb-f4de4c6581d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P9\n",
        "def pool_spec(a):\n",
        "    out = np.zeros(*a.shape)\n",
        "    for i in range(a.shape[0]):\n",
        "        out[i] = a[max(i - 2, 0) : i + 1].sum()\n",
        "    return out\n",
        "\n",
        "\n",
        "TPB = 8\n",
        "def pool_test(cuda):\n",
        "    def call(out, a, size) -> None:\n",
        "        shared = cuda.shared.array(TPB, numba.float32)\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        local_i = cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 8 lines)\n",
        "        if i < size:\n",
        "            shared[local_i] = a[i]\n",
        "        cuda.syncthreads()\n",
        "        if i < size:\n",
        "            sum = shared[local_i]\n",
        "            for t in range(1, 3):\n",
        "                if local_i - t >= 0:\n",
        "                    sum = sum + shared[local_i - t]\n",
        "                elif i - t >= 0:\n",
        "                    sum = sum + a[i - t]\n",
        "            out[i] = sum\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 8\n",
        "out = np.zeros(SIZE)\n",
        "a = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Pooling\",\n",
        "    pool_test,\n",
        "    [a],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    threadsperblock=Coord(TPB, 1),\n",
        "    blockspergrid=Coord(1, 1),\n",
        "    spec=pool_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "am8xvkvxf7nq",
        "outputId": "029bf034-f74d-4792-9663-af91e5dcf51b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P10\n",
        "def dot_spec(a, b):\n",
        "    return a @ b\n",
        "\n",
        "TPB = 8\n",
        "def dot_test(cuda):\n",
        "    def call(out, a, b, size) -> None:\n",
        "        shared = cuda.shared.array(TPB, numba.float32)\n",
        "\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        local_i = cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 9 lines)\n",
        "        if i < size:\n",
        "            a_i = a[i]\n",
        "            b_i = b[i]\n",
        "            shared[local_i] = a_i * b_i\n",
        "        cuda.syncthreads()\n",
        "        step = 1\n",
        "        while step < cuda.blockDim.x:\n",
        "            if i < size and local_i % step == 0 and i + step < size and local_i + step < cuda.blockDim.x:\n",
        "                shared[local_i] = shared[local_i] + shared[local_i + step]\n",
        "            cuda.syncthreads()\n",
        "            step = step * 2\n",
        "        if local_i == 0:\n",
        "            # out[0] = shared[local_i]\n",
        "            numba.cuda.atomic.add(out, 0, shared[local_i])\n",
        "    return call\n",
        "\n",
        "\n",
        "SIZE = 155\n",
        "out = np.zeros(1)\n",
        "a = np.arange(SIZE)\n",
        "b = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Dot\",\n",
        "    dot_test,\n",
        "    [a, b],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    threadsperblock=Coord(TPB, 1),\n",
        "    blockspergrid=Coord((SIZE + TPB - 1) // TPB, 1),\n",
        "    spec=dot_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnPRmYZ9A5CR",
        "outputId": "839f4062-9665-472c-dc56-70ecb76dc032",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P11\n",
        "def conv_spec(a, b):\n",
        "    out = np.zeros(*a.shape)\n",
        "    len = b.shape[0]\n",
        "    for i in range(a.shape[0]):\n",
        "        out[i] = sum([a[i + j] * b[j] for j in range(len) if i + j < a.shape[0]])\n",
        "    return out\n",
        "\n",
        "\n",
        "MAX_CONV = 4\n",
        "TPB = 8\n",
        "TPB_MAX_CONV = TPB + MAX_CONV\n",
        "def conv_test(cuda):\n",
        "    def call(out, a, b, a_size, b_size) -> None:\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        local_i = cuda.threadIdx.x\n",
        "\n",
        "        # FILL ME IN (roughly 17 lines)\n",
        "        shared_a = cuda.shared.array(TPB_MAX_CONV, numba.float32)\n",
        "        shared_b = cuda.shared.array(MAX_CONV, numba.float32)\n",
        "\n",
        "        if i < a_size:\n",
        "          shared_a[local_i] = a[i]\n",
        "        if local_i < b_size - 1 and i + cuda.blockDim.x < a_size:\n",
        "          shared_a[local_i + cuda.blockDim.x] = a[i + cuda.blockDim.x]\n",
        "        if local_i < b_size:\n",
        "          shared_b[local_i] = b[local_i]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        sum = 0\n",
        "        for j in range(b_size):\n",
        "          if local_i + j < cuda.blockDim.x+b_size - 1:\n",
        "            sum = sum + shared_a[local_i + j] * shared_b[j]\n",
        "        if i < a_size:\n",
        "          out[i] = sum\n",
        "    return call\n",
        "\n",
        "\n",
        "# Test 1\n",
        "\n",
        "SIZE = 6\n",
        "CONV = 3\n",
        "out = np.zeros(SIZE)\n",
        "a = np.arange(SIZE)\n",
        "b = np.arange(CONV)\n",
        "problem = CudaProblem(\n",
        "    \"1D Conv (Simple)\",\n",
        "    conv_test,\n",
        "    [a, b],\n",
        "    out,\n",
        "    [SIZE, CONV],\n",
        "    Coord(1, 1),\n",
        "    Coord(TPB, 1),\n",
        "    spec=conv_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "w88gfoTqGZrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9405371b-9d29-48cb-918c-d9e6157e5955"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2\n",
        "\n",
        "SIZE = 125\n",
        "CONV = 3\n",
        "out = np.zeros(SIZE)\n",
        "a = np.arange(SIZE)\n",
        "b = np.arange(CONV)\n",
        "problem = CudaProblem(\n",
        "    \"1D Conv (Full)\",\n",
        "    conv_test,\n",
        "    [a, b],\n",
        "    out,\n",
        "    [SIZE, CONV],\n",
        "    Coord((SIZE+TPB-1) // TPB, 1),\n",
        "    Coord(TPB, 1),\n",
        "    spec=conv_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "zSPj3GTZB1yY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bda37b6-2fcb-4499-f1fb-3549de967ce7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P12\n",
        "TPB = 8\n",
        "def sum_spec(a):\n",
        "    o = np.zeros((a.shape[0] + TPB - 1) // TPB)\n",
        "    for j, i in enumerate(range(0, a.shape[-1], TPB)):\n",
        "        o[j] = a[i : i + TPB].sum()\n",
        "    return o\n",
        "\n",
        "\n",
        "def sum_test(cuda):\n",
        "    def call(o, a, size: int) -> None:\n",
        "        cache = cuda.shared.array(TPB, numba.float32)\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        local_i = cuda.threadIdx.x\n",
        "        # FILL ME IN (roughly 12 lines)\n",
        "        if i < size: # 数据搬运\n",
        "            cache[local_i] = a[i]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        step = 1\n",
        "\n",
        "        # 算法第一部分\n",
        "        while step <= cuda.blockDim.x // 2:\n",
        "            if i < size and (local_i + 1) % (2 * step) == 0:\n",
        "                cache[local_i] = cache[local_i] + cache[local_i - step]\n",
        "            cuda.syncthreads()\n",
        "            step = step * 2\n",
        "\n",
        "        # 算法第二部分\n",
        "        while step >= 1:\n",
        "            if i < size and (local_i + 1) % (2 * step) == 0 and local_i + step < cuda.blockDim.x:\n",
        "                cache[local_i + step] = cache[local_i + step] + cache[local_i]\n",
        "            cuda.syncthreads()\n",
        "            step = step // 2\n",
        "\n",
        "        # 除了最后一段，前面每段的末尾\n",
        "        if i < size - 1 and local_i + 1 == cuda.blockDim.x:\n",
        "            o[cuda.blockIdx.x] = cache[local_i]\n",
        "        # 最后一段的末尾\n",
        "        if i == size - 1:\n",
        "            o[cuda.blockIdx.x] = cache[local_i]\n",
        "\n",
        "    return call"
      ],
      "metadata": {
        "id": "wvsNEa6UrlYu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1\n",
        "\n",
        "SIZE = 8\n",
        "out = np.zeros(1)\n",
        "inp = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Sum (Simple)\",\n",
        "    sum_test,\n",
        "    [inp],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    Coord(1, 1),\n",
        "    Coord(TPB, 1),\n",
        "    spec=sum_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "S1vzFfLwzBVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49713e8-7772-4e13-cf7f-ed82029811a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2\n",
        "\n",
        "SIZE = 16\n",
        "BLOCKS = (SIZE + TPB - 1) // TPB\n",
        "out = np.zeros(BLOCKS)\n",
        "inp = np.arange(SIZE)\n",
        "problem = CudaProblem(\n",
        "    \"Sum (Full)\",\n",
        "    sum_test,\n",
        "    [inp],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    Coord(BLOCKS, 1),\n",
        "    Coord(TPB, 1),\n",
        "    spec=sum_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "K9oD1kKyzQ_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a4fb03-d5fb-4001-c429-84e351e4bb9b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P13\n",
        "TPB = 8\n",
        "def sum_spec(a):\n",
        "    out = np.zeros((a.shape[0], (a.shape[1] + TPB - 1) // TPB))\n",
        "    for j, i in enumerate(range(0, a.shape[-1], TPB)):\n",
        "        out[..., j] = a[..., i : i + TPB].sum(-1)\n",
        "    return out\n",
        "\n",
        "\n",
        "def axis_sum_test(cuda):\n",
        "    def call(out, a, size: int) -> None:\n",
        "        cache = cuda.shared.array(TPB, numba.float32)\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        local_i = cuda.threadIdx.x\n",
        "        batch = cuda.blockIdx.y\n",
        "        # FILL ME IN (roughly 12 lines)\n",
        "        if i < size:\n",
        "            cache[local_i] = a[batch, i]\n",
        "        cuda.syncthreads()\n",
        "        step = 1\n",
        "        while step < TPB:\n",
        "            if i < size and local_i % step == 0 and local_i + step < cuda.blockDim.x and i + step < size:\n",
        "                cache[local_i] = cache[local_i] + cache[local_i + step]\n",
        "            cuda.syncthreads()\n",
        "            step = step * 2\n",
        "        if local_i == 0:\n",
        "            out[batch, i] = cache[local_i]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "    return call\n",
        "\n",
        "\n",
        "BATCH = 4\n",
        "SIZE = 6\n",
        "BLOCKS = (SIZE + TPB - 1) // TPB\n",
        "out = np.zeros((BATCH, BLOCKS))\n",
        "inp = np.arange(BATCH * SIZE).reshape((BATCH, SIZE))\n",
        "problem = CudaProblem(\n",
        "    \"Axis Sum\",\n",
        "    axis_sum_test,\n",
        "    [inp],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    Coord(BLOCKS, BATCH),\n",
        "    Coord(TPB, 1),\n",
        "    spec=sum_spec,\n",
        ")\n",
        "# problem.show()\n",
        "problem.check()"
      ],
      "metadata": {
        "id": "WiJQ7WSFaezs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4090cf1c-1ffb-464b-97ff-b0575a05d7f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P14\n",
        "def matmul_spec(a, b):\n",
        "    return a @ b\n",
        "\n",
        "\n",
        "TPB = 3\n",
        "def mm_oneblock_test(cuda):\n",
        "    def call(out, a, b, size: int) -> None:\n",
        "        a_shared = cuda.shared.array((TPB, TPB), numba.float32)\n",
        "        b_shared = cuda.shared.array((TPB, TPB), numba.float32)\n",
        "\n",
        "        i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "        j = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "        local_i = cuda.threadIdx.x\n",
        "        local_j = cuda.threadIdx.y\n",
        "        # FILL ME IN (roughly 14 lines)\n",
        "        tiles = (size + TPB - 1) // TPB\n",
        "\n",
        "        sum = 0\n",
        "        for t in range(tiles):\n",
        "            a_t = 0\n",
        "            b_t = 0\n",
        "            k = t * TPB + local_i\n",
        "            # 搬运的条件很容易出错！\n",
        "            if j < size and k < size:\n",
        "                a_t = a[j, k]\n",
        "            k = t * TPB + local_j\n",
        "            if i < size and k < size:\n",
        "                b_t = b[k, i]\n",
        "            a_shared[local_j, local_i] = a_t\n",
        "            b_shared[local_j, local_i] = b_t\n",
        "            cuda.syncthreads()\n",
        "\n",
        "            if i < size and j < size:\n",
        "                for s in range(TPB):\n",
        "                    sum = sum + a_shared[local_j, s] * b_shared[s, local_i]\n",
        "            cuda.syncthreads() # 这个同步很容易漏掉！\n",
        "        if i < size and j < size:\n",
        "            out[j, i] = sum\n",
        "\n",
        "    return call\n",
        "\n",
        "# # Test 1\n",
        "\n",
        "SIZE = 2\n",
        "out = np.zeros((SIZE, SIZE))\n",
        "inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
        "inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T\n",
        "\n",
        "problem = CudaProblem(\n",
        "    \"Matmul (Simple)\",\n",
        "    mm_oneblock_test,\n",
        "    [inp1, inp2],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    Coord(1, 1),\n",
        "    Coord(TPB, TPB),\n",
        "    spec=matmul_spec,\n",
        ")\n",
        "# problem.show(sparse=True)"
      ],
      "metadata": {
        "id": "du938Y60oJfm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7U8dYXBUwYS",
        "outputId": "f3a35eec-d635-48ad-c287-00da5476fe81"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 8\n",
        "out = np.zeros((SIZE, SIZE))\n",
        "inp1 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
        "inp2 = np.arange(SIZE * SIZE).reshape((SIZE, SIZE)).T\n",
        "\n",
        "problem = CudaProblem(\n",
        "    \"Matmul (Full)\",\n",
        "    mm_oneblock_test,\n",
        "    [inp1, inp2],\n",
        "    out,\n",
        "    [SIZE],\n",
        "    Coord(3, 3),\n",
        "    Coord(TPB, TPB),\n",
        "    spec=matmul_spec,\n",
        ")\n",
        "# problem.show(sparse=True)"
      ],
      "metadata": {
        "id": "PCJ-LutOUzpY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRAKFxn9U1fg",
        "outputId": "ab996be0-a9f6-4cff-9d9d-d62bfc6e6ac9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Tests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1HvtEWiqiBIt"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}